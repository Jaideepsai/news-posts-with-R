#setwd("C:/Users/SONY/Desktop/Social Media Project/CnnData")
dataDir <- "C:/Users/SONY/Desktop/Social Media Project/CnnData"
setwd(dataDir)
urls <- read.csv(file.path(dataDir,"urls.csv"))
load("cnn.Rdata")

# Get the list of all text files containing the full content of a post

textfiles <- list.files(pattern = '.txt')

#Use Library "tool" to get the name of the file only by omiting the file extension name using "file_path_sans_ext" command
library(tools)

#Create a new variable called contents in the dataframe and then Initiaize the variable with NAs

urls["Contents"] <- NA

#Initiaization of variables

x  <- length(urls$value)
m  <- length(urls$value)

# Loop to read and write the full content of each link with the master data table

for ( k in 1:x)
{
  for(l in 1:m)
  {
    y <- file_path_sans_ext(textfiles[l])
    
    #By Pass Text Files with no contents
    
    if(any(is.na(textfiles[l])))
    {

      next
    }
    print (paste(urls$value[k],l,y))
    if(urls$value[k] ==  y)
  
      {urls$Contents[k] <- readLines(textfiles[l])
     # print (paste(urls$value[k],k,y))      
      break
    }
    else {
      
      next}
    
  }
}

# omit all rows with NAs
urls1 <- na.omit(urls)

# merge data frame with full content with emoji counts using link variable
finaldata <- merge(fb_page,urls1,by = "link")

save.image("file = "CnnContent.RData") 
