#setwd("C:/Users/SONY/Desktop/Social Media Project/CnnData")
dataDir <- "C:/Users/SONY/Desktop/Social Media Project/CnnData"
setwd(dataDir)
urls <- read.csv(file.path(dataDir,"urls.csv"))
load("cnn.Rdata")

# Get the list of all text files containing the full content of a post

textfiles <- list.files(pattern = '.txt')

#Use Library "tool" to get the name of the file only by omiting the file extension name using "file_path_sans_ext" command
library(tools)

#Create a new variable called contents in the dataframe and then Initiaize the variable with NAs

urls["Contents"] <- NA

#Initiaization of variables

x  <- length(urls$value)
m  <- length(urls$value)

# Loop to read and write the full content of each link with the master data table

for ( k in 1:x)
{
  for(l in 1:m)
  {
    y <- file_path_sans_ext(textfiles[l])
    
    #By Pass Text Files with no contents
    
    if(any(is.na(textfiles[l])))
    {

      next
    }
    print (paste(urls$value[k],l,y))
    if(urls$value[k] ==  y)
  
      {urls$Contents[k] <- readLines(textfiles[l])
     # print (paste(urls$value[k],k,y))      
      break
    }
    else {
      
      next}
    
  }
}

# omit all rows with NAs
urls1 <- na.omit(urls)

# merge data frame with full content with emoji counts using link variable
finaldata <- merge(fb_page,urls1,by = "link")

save.image("file = "CnnContent.RData") 

#Create Document term Matrix

library('dplyr')

#if you do not have the above package then install it

#create a dataframe

text_df<-data_frame(line=1:length(finaldata$Contents), text=finaldata$Contents)

# divide the text into single words in a data frame
library('tidytext')

text_df2 <- text_df %>% unnest_tokens(word,text)

# remove any NA
text_df3<- na.omit(text_df2)

#remove stop words
data(stop_words)
text_df4 <- text_df3 %>% anti_join(stop_words)

# add the count 
ap_td <- text_df4 %>% group_by(line,word) %>% tally()

library('tm')

#added by vivek
#to create a document term matrix for prediction
m_data1 <- ap_td %>% cast_sparse(line, word, n)
